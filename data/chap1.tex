\chapter{背景和动机}
\label{cha:back}

\section{卷积神经网络}
    卷积神经网络是目前在图像检测、图像分类等领域最先进的方法\cite{mcdnn, yolo}。通常，卷积神经网络分成不同的层、包括卷积层、池化层、全连接层等。以LeNet\cite{lenet}进行手写数字识别为例，输入是一组$ 28 \times 28 $的图片，输出是一个矩阵，表示该图片属于这个数字的概率。一般我们认为，卷积操作是对图片局部特征的提取，而全连接层统合整体数据，给出预测信息。这两个操作贡献了卷积神经网络中计算时间的绝对多数。
    
    现有最先进的卷积神经网络通常具有巨大的参数量和运算量，如ResNet\cite{resnet}。在这种情况下使用单机CPU就很难对网络进行训练。通常情况下，我们常用的做法是在一台机器上配置张显卡作为深度学习工作站。而随着大批量训练方式的日益成熟\cite{bigbatch}，为了追求更高的精度和更快的训练速度，很多时候单机工作站也不能满足我们的需要。现在的人工智能相关企业通常会自己维护自己的深度学习集群。而对于个人用户或是小企业而言，维护一个深度学习集群成本上是不可接受的，也是不划算的，因此现在很多用户会使用云上的资源进行深度神经网络的训练。

\section{在云上进行机器学习}
    通常在云上部署机器学习应用有两种方式。第一种是租用云服务器，如亚马逊的AWS EC2服、阿里云ECS等，然后在上面自行搭建机器学习框架，如TensorFlow等。另一种是直接使用云服务商提供的机器学习平台，如亚马逊的AWS Machine Learning、阿里云的PAI等。而无论使用哪种平台，云服务商都会根据你的使用情况进行收费。如果能得到在特定平台上深度学习任务的运行时间，可以帮助用户选择更合适的平台，如价格更便宜或速度更快。
    
    因此，深度学习任务性能预测对云平台非常重要。
    
\section{机器学习框架}
    在本地训练时，通常我们都需要机器学习框架。机器学习框架可以帮助用户节省大量的代码编写时间，用户可以不需要花费精力去编写大量的计算代码，而只需要关注模型结构即可。另一方面，在机器学习框架的组织下，可以更好地对操作进行优化。以TensorFlow为例，TensorFlow中的运算以数据流图的形式进行组织。其中的操作通过Stream Executor进行执行。在这个过程中，Stream Executor通过不同的函数调用方式，对TensorFlow中的计算任务进行优化。
    
    尽管TensorFlow在执行过程中存在这类优化，但是TensorFlow在操作执行的调度层面并没有进行优化。调度优化需要对操作的执行时间有预估。机器学习任务一般只执行一次，因此在这种情况下，通常编译优化使用的通过运行拿到性能数据的方式并不适合。这种情况下，我们对操作的运行时间进行建模，结合运行前已经确定好的执行数据的规模，我们就可以在静态拿到每个操作的运行时间。结合已经确定好的数据流图，我们可以对TensorFlow这类平台进行操作粒度的调度优化。

\section{我们的方法}
    我们的工作在TensorFlow上进行，主要针对卷积神经网络进行性能预测。
    
    首先，我们在不同的平台上，对TensorFlow的部分操作进行性能建模，从而可以在静态分析中拿到图中节点的运行时间。

    之后，我们模拟TensorFlow的运行过程，从用户输入的模型定义，生成数据流图。结合我们预测的平台对应的操作的性能模型，我们拿到每个操作的运行时间，进而预测TensorFlow的调度过程，模拟模型的运行时间。

\section{相关工作}
\subsection{数据流图}
    数据流图是应用程序并行运行的一种组织方式。通常，数据流图是一个有向无环图。数据流图的点表示一个运算，即一个操作，而边表示数据路径。这种组织方式能够明确的显示运算之间的依赖关系，方便程序进行调度。在TensorFlow中，数据流图的节点表示一个操作，而在TensorFlow的调度中，数据流图中的节点会被预先分配到某个节点的某个设备上，再通过Stream Executor进行执行。

\subsection{Stream Executor}
    Stream Executor是Google对CUDA和OpenCL进行的封装。它能够管理任务的并行执行，同时保证同一套代码能够运行在不同的设备上。TensorFlow使用的是Stream Executor的简化版本，而在TensorFlow中，所有操作都使用Stream Executor进行调度，因此用户可以不需要直接对设备进行管理，实际使用中，Tensorflow的Stream Executor模块在GPU运行时主要工作就是将矩阵乘法、二维卷积等操作映射到CUBlas或CUDNN\cite{cudnn}的函数。
    