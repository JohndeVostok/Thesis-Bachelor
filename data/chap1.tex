\chapter{相关工作}
\label{cha:related}

\section{卷积神经网络}
    卷积神经网络是目前在图像检测、图像分类等领域最先进的方法\cite{mcdnn, yolo}。通常，卷积神经网络分成不同的层、包括卷积层、池化层、全连接层等。以LeNet\cite{lenet}进行手写数字识别为例，输入是一组$ 28 \times 28 $的图片，输出是一个矩阵，表示该图片属于这个数字的概率。一般我们认为，卷积操作是对图片局部特征的提取，而全连接层统合整体数据，给出预测信息。这两个操作贡献了卷积神经网络中计算时间的绝大多数。
    
    现有最先进的卷积神经网络通常具有巨大的参数量和运算量，如ResNet\cite{resnet}。在这种情况下使用单机CPU就很难对网络进行训练。通常情况下，我们常用的做法是在一台机器上配置多张显卡作为深度学习工作站。而随着大批量训练方式的日益成熟\cite{bigbatch}，为了追求更高的精度和更快的训练速度，很多时候单机工作站也不能满足我们的需要。现在的人工智能相关企业通常会自己维护自己的深度学习集群。而对于个人用户或是小企业而言，维护一个深度学习集群成本上是不可接受的，也是不划算的，因此现在很多用户会使用云上的资源进行深度神经网络的训练。

\section{在云上进行机器学习}
    通常在云上部署机器学习应用有两种方式。第一种是租用云服务器，如亚马逊的AWS EC2、阿里云ECS等，然后在上面自行搭建机器学习框架，如TensorFlow等。另一种是直接使用云服务商提供的机器学习平台，如亚马逊的AWS Machine Learning、阿里云的PAI等。在云上，可预测性是一个非常重要的指标\cite{cloud, serverless}。无论使用哪种服务，云服务商都会根据你的使用情况进行收费，如租用AWS的EC2服务需要按实例启动时间收费，使用AWS Lambda需要按程序运行时间收费，为阿里云的PAI这样的机器学习平台通常根据运行时间收费。
    
\section{机器学习框架}
    在本地训练时，通常我们都需要机器学习框架。机器学习框架可以帮助用户节省大量的代码编写时间，用户可以不需要花费精力去编写大量的计算代码，而只需要关注模型结构即可。另一方面，在机器学习框架的组织下，可以更好地对操作进行优化。以TensorFlow为例，TensorFlow中的运算以数据流图的形式进行组织。其中的操作通过Stream Executor进行执行。在这个过程中，Stream Executor通过不同的函数调用方式，对TensorFlow中的计算任务进行优化。
    
    尽管TensorFlow在执行过程中存在各类优化，但是TensorFlow在操作执行的调度层面并没有进行优化。调度优化需要对操作的执行时间有预估。机器学习任务一般只执行一次，因此在这种情况下，通常编译优化使用的通过运行得到性能数据的方式并不适合。这种情况下，我们对操作的运行时间进行建模，结合运行前已经确定好的执行数据的规模参数，我们就可以在静态拿到每个操作的运行时间。结合已经确定好的数据流图，我们可以对TensorFlow这类平台进行操作粒度的调度优化。

\section{数据流图}
    数据流图通常被用来作为复杂程序的抽象。早在80年代，就有基于数据流图模型的计算机\cite{dataflow_machine}。通常，数据流图是一个有向无环图。图上的一个点表示一个运算，在TensorFlow中即为一个操作。图上的边表示数据或依赖关系，如用户指定操作A必须在操作B开始执行前执行完毕，可以在操作A和B之间连一条边，即可表示两者的执行顺序。
    
    数据流图的好处在于，图上的点运行过程中互不依赖，而点与点之间的依赖关系以图上的边的形式表示，能够非常方便的进行调度。在TensorFlow中，数据流图中的节点在调度过程中会被预先分配到某个节点的某个设备上，再通过Stream Executor进行执行。

\section{Stream Executor}
    Stream Executor是Google对CUDA和OpenCL进行的封装。它能够管理任务的并行执行，同时保证同一套代码能够运行在不同的设备上。TensorFlow使用的是其简化版本。

    在TensorFlow中，所有操作都使用Stream Executor进行执行，因此用户可以不需要直接对设备进行管理。具体地，在使用GPU时，Stream Executor模块会将矩阵乘法、二维卷积等操作映射到CUBlas或CUDNN\cite{cudnn}的函数。
    
    性能模型部分本质上就是对Stream Executor进行预测。
    