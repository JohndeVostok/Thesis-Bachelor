\chapter{外文资料的调研阅读报告}
\title{TensorFlow}

\section{引言}
人工智能在当今社会中应用越来越广泛，机器学习的地位与日俱增。深度神经网络在计算机视觉、自然语言处理等领域都有广泛的应用。随着数据规模和网络规模的日益扩大，以及异构平台的广泛使用，机器学习框架的重要性与日俱增。现有的机器学习框架有很多，如TensorFlow、Caffe、Torch、Theano等。本文将对TensorFlow进行简单的介绍。

\section{历史}
2010年Google就开发了他们的第一代机器学习系统DistBelief。这一系统在Google的搜索、广告、翻译等多个服务中都有广泛的应用。后来在Jeff Dean等人在DistBelief的基础上进行优化，创造了TensorFlow。现在TensorFlow已经代替DistBelief成为Google主要使用的系统。

\section{介绍}
TensorFlow的名字来源于TensorFlow的运行过程。Tensor是张量的意思，可以理解为一个多维数组。TensorFlow的计算被组织成数据流图的形式，Tensor穿梭于图上的节点之间，就像流动一样，所以起名TensorFlow。

\section{为什么要使用TensorFlow}
在我们执行机器学习任务的时候，用户往往更关注的是模型的效果、如收敛时间、精确度、等信息，而不是模型该如何部署到大规模的集群，如何处理运行间的错误等。如果使用C++进行过神经网络的编写，你就会知道，一个仅仅几层的神经网络，从正向预测到反向传播，整个代码会有几百行之长。这是机器学习算法工程师不能接受的，严重阻碍了机器学习的发展。另一方面，机器学习任务的模型本身通常是不受平台限制的。比如同样的一个网络，可以运行在单机CPU，也可以执行在大规模异构集群上，而部署阶段甚至可以运行在边缘设备，如手机等平台上。这对数据和模型的变化可能仅仅在于一两个参数的变化，但是如果没有机器学习框架的帮助，需要重复在不同平台上实现多个不同版本。

Tensorflow给用户主要提供了两个功能。一个是提供给用户简单易用的编程接口，方便用户在使用的时候定义机器学习任务。另一个是帮助用户执行模型。在TensorFlow中，系统预先定义了大量操作，用户可以使用TensorFlow提供的基本原语，非常容易地创建机器学习任务，不需要关心过多的细节。同时TensorFlow提供了执行框架，相同的机器学习任务可以轻松的移植到不同的平台，从手机到大规模异构集群，仅仅需要少量的改动即可使用

\section{数据流图}
数据流图是一个古老的工具，在80年代就有人使用数据流图来进行并行计算。本世纪初，数据流图经历了历史的寒冬，正如人工智能所经历的一样。近些年，计算力的大幅提升、以及异构平台的大量使用，给了数据流图新的历史发展机遇。

数据流图的好处在于，能够将复杂的计算任务高度抽象，节点间的运行互不影响。在这个前提下，任务能够被比较好地调度到不同的设备上进行执行。

现在，大量最先进的数据处理系统，都使用数据流图作为编程模型，或数据的抽象模型。如Spark、Flink等。

\section{TensorFlow的编程模型}
TensorFlow中机器学习任务被组织成数据流图的形式。数据流图是一个有向无环图，其中图上的节点表示TensorFlow中定义好的一个运算操作，图上的边表示数据在节点之间的流动过程。特别地，在TensorFlow中，数据被以张量（Tensor）的形式存储。图上的边不仅表示数据的流动过程，还同时表示了操作之间的依赖关系。另外，TensorFlow的数据流图中还有另一种边，它没有数据经过，用来限制计算之间的顺序关系，这种边被称作控制依赖。

\section{操作与核函数}
在我们定义机器学习任务的时候，我们使用了TensorFlow中提供的各类操作。这些操作只是标记了一种运算方式。我们在执行计算任务的时候，操作可能会被映射到不同的实现上。这些实现被称作核函数。

一般情况下，核函数和操作以及设备进行绑定。一个操作可能对应多个核函数，每个核函数对应一种类型的设备。大部分的核函数使用Eigen实现，在GPU上很多核函数是用CuBlas和CuDNN函数实现的，因此TensorFlow能够在不同平台上都有比较不错的运行性能。

\section{会话}
会话是TensorFlow中的重要交互工具。会话主要提供两个基本功能：数据流图的创建和数据流图的执行接口。一般情况下，TensorFlow对每一个数据流图都会对应一个会话。在多次计算数据流图的时候，反复通过会话的启动命令进行运行。在会话的执行操作中，TensorFlow对数据流图进行处理、分配、以及运行过程。

\section{TensorFLow的实现}
TensorFlow的计算和客户端是分开的，用户定义计算任务是在客户端进行的。用户在客户端可以通过会话连接master，向master提交任务，传输数据流图。Master对数据流图进行处理，再发送给worker。Worker根据得到的计算任务分配到本地设备，分别执行对应的核函数。

其中，master在拿到任务后，先进行一次剪枝操作。在这步操作中，TensorFlow执行DFS算法，将不会被执行到的操作去除。之后，根据平台的配置情况将处理过的图切分，分配到不同的worker上。例如单机的时候，worker仅有一个，就会直接将图传送给worker进程。而在分布式部署的时候，就会将切分好的图分配到不同的worker上。Worker在拿到被分配的子图后，还会进行第二次切分，将节点切分到不同的设备上，再调用数据流图执行算法。

单机单设备执行过程，单机单GPU执行是最简单的情况。这时候客户端、master和worker都是本地的一个进程。这时模型最为简单，有一个队列用来存放待执行任务。每一个待执行任务都有一个依赖计数器。每当一个任务被执行完成的时候，就给他的出边对应的待执行操作的计数器减1。当依赖计数器为0的时候，这一个操作就可以被调度执行，调用当前设备上该操作对应的核函数。

单机多设备执行过程，在单机多设备的执行过程中，多了两个问题，一个是操作在哪个设备上执行。另一个是设备之间的数据依赖关系。通常，无论采用数据并行，还是模型并行。用户都需要提前指定操作被执行的设备。数据依赖上，多设备执行的时候，设备需要的数据可能存储在其他设备上，这时候需要插入send和receive节点，来进行数据的传输。Send/receive节点的插入有多种策略，并不一定在所有的数据依赖上都插入。其中允许的一种调度方式是定时以同步的方式在设备间传输数据。这种情况系统的可扩展性会更好。

分布式系统执行。分布式系统和多设备类似，只不过跨设备的数据依赖插入的send/receive节点以TCP或RDMA方式进行。

\section{总结}

TensorFlow是目前使用非常广泛的机器学习框架，我的毕设将在TensorFlow的基础上进行。目前，TensorFlow的调度过程可以比较容易地被模拟，我们在一系列实测操作数据的基础上就可以对TensorFlow的运行时间进行预测。我的毕设将在这一思想的基础上实现深度神经网络的性能预测。

\title{参考文献}

\begin{translationbib}
    \item ABADI M, BARHAM P, CHEN J, et al. Tensorflow: A system for large-scale machinelearning[C]//12thfUSENIXgSymposium on Operating Systems Design and Implementation(fOSDIg16). 2016: 265-283.
    \item ABADI M, AGARWAL A, BARHAM P, et al. TensorFlow: Large-scale machine learningon heterogeneous systems[EB/OL]. 2015.http://tensorflow.org/.
    \item BAHRAMPOUR S, RAMAKRISHNAN N, SCHOTT L, et al. Comparative study of deeplearning software frameworks[J]. arXiv preprint arXiv:1511.06435, 2015.
\end{translationbib}