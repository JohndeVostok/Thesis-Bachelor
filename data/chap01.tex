\chapter{介绍}
\label{cha:intro}

\section{动机}
\label{sec:motivation}
    随着机器学习的发展，深度神经网络有了越来越广泛的应用，如在机器视觉，自然语言处理等领域。于此同时，深度神经网络的深度和规模都越来越大，因此，深度神经网络的运行需要{\bfseries 更大规模的运算设备以及更长的运行时间}。那么，选择哪种设备或知道在固定设备上，模型的运行时间，就成了一个重要的问题。

    运行机器学习应用有两种不同的模式。在本地设备运行或在云平台运行。通常，企业会有自己的设备集群，并配备相应的管理方式。这种情况下，计算资源成为了企业内部争抢的资源，这时如何进行任务层面的调度，就成为了一个非常重要的问题。而更准确的离线性能预测模型，能够给企业提供更好的调度效果，提高工作效率。
    
    另一方面，当资金比较缺乏，不能够自己组建设备，或需要的计算资源规模太大(如Facebook 2018年的工作一样，使用256块GPU在1小时内训练ImageNet)。这些情况下，在本地运行都不现实，因此，使用云计算平台成为了非常合适的解决方案。
    
    云计算平台上通常提供了现成的机器学习应用框架，如AWS Machine Learning, Azure Machine Learning等，他们提供了从现有模型导入到云计算平台运行的功能。而另一种方式是直接租用实例（如AWS EC2等）搭建机器学习框架进行运行。无论使用哪种方式，现有的云计算平台都是按照时间收费的。因此，预测模型在不同设备上的运行时间，能够帮助用户更好的规划资金，选择配置。
    
    而另一方面，现有的机器学习框架，如tensorflow等，在集群模式下，通常使用数据并行方式进行加速。而在模型并行模式下，由于缺少操作性能数据模型，不能得到每个操作较为准确的运行时间，限制了模型并行的细粒度调度。因此，在进行细粒度性能预测的过程中，模型能够给机器学习框架提供细粒度调度建议，提高模型并行的运行速度。
    
    综上所述，深度神经网络性能预测模型无论是对工业界还是学术界都很重要。

\section{相关工作}
\label{sec:related}

\subsection{TensorFlow}
    TensorFlow是一个端到端的开源机器学习平台。用户在已经配置好的tensorFlow平台上，可以定义模型并运行，不需要过多的考虑硬件设备。TensorFlow的模型主要分为两部分，数据以及运算，数据以张量（tensor）的形式保存，运算以数据流图(data flow graph)的形式进行组织，TensorFlow在运行过程中，根据硬件设备对数据流图进行调度，并通过stream executor进行执行。
    
    用户在使用TensorFlow的时候，只需要定义需要的运算即可，TensorFlow会自动将用户定义的运算转换为Graph（如图所示）。
    
\subsection{数据流图}

\section{我们的方法以及贡献}